import numpy as np
import matplotlib.pyplot as plt
from matplotlib import colormaps as cm
from matplotlib.patches import Rectangle
from scipy.io import loadmat
from scipy.spatial.distance import pdist, squareform
from scipy.ndimage import gaussian_filter1d
import os
from copy import deepcopy
import esig


def lead_lag_transformation(x, k: int = 1):
    x = np.repeat(x, 2*k)
    return np.vstack((x[k:], x[:-k]))


def get_unique_key(key: int, keys: list) -> int:
    if key in keys:
        return np.max(keys)+1
    return key


def split_into_modules(A: np.ndarray, P: np.ndarray, modules: dict, m: int, iteration: int = 0, max_iter: int = 100,
                       min_nodes: int = 2) -> dict:
    modules_new = {}
    B = A - P
    for key, (nodes, Q_old) in deepcopy(modules).items():

        if Q_old > 0:

            # calculate difference matrix
            B_tmp = B[nodes, :][:, nodes]
            if iteration > 0:
                for n in range(B_tmp.shape[0]):
                    B_tmp[n, n] -= np.sum(B_tmp[n, :])

            # eigenvalue decomposition of difference matrix
            eigs, vectors = np.linalg.eig(B_tmp)
            idx_max = np.argmax(eigs)

            # sort nodes into two modules
            idx = vectors[:, idx_max] >= 0
            s = np.zeros_like(nodes)
            s[idx == True] = 1
            s[idx == False] = -1

            # calculate modularity
            Q_new = s.T @ B_tmp @ s

            # decide whether to do another split or not
            if Q_new > 0 and iteration < max_iter and np.sum(idx == True) >= min_nodes \
                    and np.sum(idx == False) >= min_nodes:

                modules_new[get_unique_key(key, list(modules_new))] = (nodes[np.argwhere(s > 0)[:, 0]], Q_new)
                modules_new[get_unique_key(key, list(modules_new))] = (nodes[np.argwhere(s < 0)[:, 0]], Q_new)
                modules_new = split_into_modules(A, P, modules_new, m, iteration + 1, min_nodes=min_nodes,
                                                 max_iter=max_iter)

            else:
                modules_new[get_unique_key(key, list(modules_new))] = (nodes, -1.0)

        else:
            modules_new[get_unique_key(key, list(modules_new))] = (nodes, -1.0)

    return modules_new


def get_modules(A: np.ndarray, **kwargs) -> dict:

    # calculating the null matrix to compare against
    P = np.zeros_like(A)
    N = A.shape[0]
    m = int(np.sum(np.tril(A) > 0))
    for n1 in range(N):
        for n2 in range(N):
            k1 = np.sum(A[n1, :] > 0)
            k2 = np.sum(A[n2, :] > 0)
            P[n1, n2] = k1 * k2 / (2 * m)

    # find modules
    return split_into_modules(A, P, {1: (np.arange(0, N), 1)}, m, 0, **kwargs)


def sort_via_modules(A: np.ndarray, modules: dict) -> np.ndarray:
    """Sorts adjacancy matrices such as the one generated by `modularity()` according to the module dictionary returned
    by `modularity()`.

    :param A: Adjacancy matrix (N x N)
    :param modules: Dictionary containing module indices as keys and node lists in the value tuple.
    :return: N x N sorted matrix containing the module keys as entries.
    """

    # collect node order and create new matrix that contains the module indices as entries
    node_order = []
    for module, (nodes_tmp, _) in modules.items():
        node_order.extend(list(nodes_tmp))

    # sort the new matrix according to the collected node order
    C1 = np.zeros_like(A)
    for i, n in enumerate(node_order):
        C1[i, :] = A[n, :]
    C2 = np.zeros_like(A)
    for i, n in enumerate(node_order):
        C2[:, i] = C1[:, n]

    return C2


# choose condition
drug = "SKF38393"
dose = "Vehicle"
mouse_id = "972"
fields = ["events_5hz", "cellXYcoords_um"]

# load data
max_neurons = 300
data = {}
path = "/run/user/1000/gvfs/smb-share:server=fsmresfiles.fsm.northwestern.edu,share=fsmresfiles/Basic_Sciences/Phys/Kennedylab/Parkerlab/Calcium_v2"
for file in os.listdir(f"{path}/{drug}/{dose}"):
    if mouse_id in file:
        condition = "amph" if "amph" in file else "veh"
        data_tmp = loadmat(f"{path}/{drug}/{dose}/{file}/{condition}_drug.mat", simplify_cells=True)
        data[condition] = {field: data_tmp[f"{condition}_drug"][field][:max_neurons, :] for field in fields}

# apply lead-lag transform to the time series data and interpolate over time
k = 1
t0, t1 = 2000, 3000
for key in data:
    traces = data[key][fields[0]][:, t0:t1]
    time = np.arange(0, (k+1)*traces.shape[1]-k)
    leads, lags = [], []
    for i in range(traces.shape[0]):
        lead, lag = lead_lag_transformation(traces[i, :], k=k)
        leads.append(lead)
        lags.append(lag)
    data[key]["leads"] = leads
    data[key]["lags"] = lags

# calculate signatures of lead-lag transformed data
depth = 2
for key in data:
    signatures = []
    for lead, lag in zip(data[key]["leads"], data[key]["lags"]):
        stream = np.asarray([lead, lag], dtype=np.float64).T
        s = esig.stream2sig(stream, depth)
        signatures.append(s)
    data[key]["s"] = np.asarray(signatures)

# calculate distances and similarities
for key in data:

    # similarity based on path signatures
    S = squareform(pdist(data[key]["s"], metric="euclidean"))
    idx = np.isfinite(S)
    S = 1 - S / np.max(S[idx])
    S[~idx] = 0.0
    data[key]["S"] = S

    # spatial distance based on coordinates
    data[key]["D"] = squareform(pdist(data[key][fields[-1]], metric="euclidean"))

    # similarity based on time series
    C = squareform(pdist(data[key][fields[0]][:, t0:t1], metric="cosine"))
    idx = np.isfinite(C)
    C = 1 - C / np.max(C[idx])
    C[~idx] = 0.0
    data[key]["C"] = C

# identify communities based on distance matrix
threshold = 0.15
min_nodes = 10
max_iter = 100
measure = "C"
for key in data:

    # translate similarity matrix into adjacency matrix
    S = data[key][measure]
    A = np.zeros_like(S)
    A[S < threshold] = 0.0
    A[S >= threshold] = 1.0

    # detect communities
    comms = get_modules(A, min_nodes=min_nodes, max_iter=max_iter)
    data[key]["communities"] = comms
    data[key]["A"] = A

# plotting
sr = 5
n_ticks = 5
sigma = 3
cbar_shrink = 0.6
for key in data:

    # get data
    S = data[key][measure]
    D = data[key]["D"]
    A = data[key]["A"]
    signal = data[key][fields[0]][:, t0:t1]
    communities = data[key]["communities"]

    # apply community structure to data
    S = sort_via_modules(S, communities)
    D = sort_via_modules(D, communities)
    A = sort_via_modules(A, communities)

    # initialize figure
    fig = plt.figure(figsize=(12, 8))
    fig.suptitle(f"Mouse: {mouse_id}, drug: {drug}, dose: {dose}")
    grid = fig.add_gridspec(nrows=3, ncols=3)

    # plot similarity matrix
    ax1 = fig.add_subplot(grid[:2, 0])
    im = ax1.imshow(S, interpolation="none", cmap="magma", aspect="equal", vmax=np.max(S[np.eye(S.shape[0]) < 0.5]))
    plt.colorbar(im, ax=ax1, shrink=cbar_shrink)
    ax1.set_xlabel("neuron")
    ax1.set_ylabel("neuron")
    ax1.set_title(f"Similarities for cond: {key}")

    # plot adjacency matrix
    ax2 = fig.add_subplot(grid[:2, 1])
    im = ax2.imshow(A, interpolation="none", cmap="magma", aspect="equal")
    plt.colorbar(im, ax=ax2, shrink=cbar_shrink)
    ax2.set_xlabel("neuron")
    ax2.set_ylabel("neuron")
    ax2.set_title(f"Adjacencies for cond: {key}")

    # plot distance matrix
    ax3 = fig.add_subplot(grid[:2, 2])
    im = ax3.imshow(D, interpolation="none", cmap="magma", aspect="equal")
    plt.colorbar(im, ax=ax3, shrink=cbar_shrink)
    ax3.set_xlabel("neuron")
    ax3.set_ylabel("neuron")
    ax3.set_title(f"Spatial distance for cond: {key}")

    # plot community dynamics
    ax4 = fig.add_subplot(grid[2, :])
    cmap = cm.get_cmap('tab10')
    x, y = 0, 0
    for c, (indices, _) in communities.items():
        mean_signal = gaussian_filter1d(np.mean(signal[indices, :], axis=0), sigma=sigma)
        ax4.plot(mean_signal, c=cmap(c - 1), label=f"c{c}")
        inc = len(indices)
        for ax in [ax1, ax2, ax3]:
            rect = Rectangle([x, y], inc, inc, edgecolor=cmap(c - 1), facecolor='none')
            ax.add_patch(rect)
        x += inc
        y += inc

    sig = gaussian_filter1d(np.mean(signal, axis=0), sigma=sigma)
    ax4.plot(sig, c='black', label="mean")
    xticks = np.linspace(0, len(sig), n_ticks)
    ax4.set_xticks(xticks, labels=[int(tick / sr) for tick in xticks])
    ax4.set_xlabel("time (s)")
    ax4.set_ylabel("signal")
    ax4.set_title(f"Average community dynamics for cond: {key}")
    ax4.legend()
    plt.tight_layout()

plt.show()
